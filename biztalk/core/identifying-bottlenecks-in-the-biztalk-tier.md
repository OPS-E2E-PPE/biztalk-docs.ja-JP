---
title: BizTalk 層のボトルネックの特定 |Microsoft Docs
ms.custom: ''
ms.date: 06/08/2017
ms.prod: biztalk-server
ms.reviewer: ''
ms.suite: ''
ms.tgt_pltfrm: ''
ms.topic: article
ms.assetid: f38ade78-8af3-4485-9b2a-5e4cdba965d2
caps.latest.revision: 10
author: MandiOhlinger
ms.author: mandia
manager: anneta
ms.openlocfilehash: 8b53410466478ea7e493d043f42b5de86ec9921c
ms.sourcegitcommit: 266308ec5c6a9d8d80ff298ee6051b4843c5d626
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/27/2018
ms.locfileid: "36996251"
---
# <a name="identifying-bottlenecks-in-the-biztalk-tier"></a><span data-ttu-id="221fb-102">BizTalk 層のボトルネックの特定</span><span class="sxs-lookup"><span data-stu-id="221fb-102">Identifying Bottlenecks in the BizTalk Tier</span></span>
<span data-ttu-id="221fb-103">BizTalk 層は以下の機能領域に分割できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-103">The BizTalk tier can be divided into the following functional areas:</span></span>  
  
- <span data-ttu-id="221fb-104">受信</span><span class="sxs-lookup"><span data-stu-id="221fb-104">Receiving</span></span>  
  
- <span data-ttu-id="221fb-105">処理</span><span class="sxs-lookup"><span data-stu-id="221fb-105">Processing</span></span>  
  
- <span data-ttu-id="221fb-106">送信</span><span class="sxs-lookup"><span data-stu-id="221fb-106">Transmitting</span></span>  
  
- <span data-ttu-id="221fb-107">Tracking</span><span class="sxs-lookup"><span data-stu-id="221fb-107">Tracking</span></span>  
  
- <span data-ttu-id="221fb-108">その他</span><span class="sxs-lookup"><span data-stu-id="221fb-108">Other</span></span>  
  
  <span data-ttu-id="221fb-109">これらの領域でシステム リソース (CPU、メモリ、およびディスク) が飽和状態になっている場合は、スケール アップによってサーバーをアップグレードします。</span><span class="sxs-lookup"><span data-stu-id="221fb-109">For these areas, if the system resources (CPU, memory, and disk) appear to be saturated, upgrade the server by scaling up.</span></span> <span data-ttu-id="221fb-110">システム リソースが飽和状態になっていない場合は、ここで説明する手順を実行します。</span><span class="sxs-lookup"><span data-stu-id="221fb-110">If the system resources are not saturated, perform the steps described in this section.</span></span>  
  
## <a name="bottlenecks-in-the-receive-location"></a><span data-ttu-id="221fb-111">受信場所のボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-111">Bottlenecks in the Receive Location</span></span>  
 <span data-ttu-id="221fb-112">受信場所でメッセージが蓄積され始めている場合 (ファイル受信フォルダーのサイズが大きくなっている場合や、送信キューの排出が遅い場合など) は、システムがデータを取り込む速度が不十分なため、受信の負荷に対応できていないことを示します。その原因としては内部の制限が考えられます (BizTalk では、サブスクライバーのデータ処理の遅れによりデータベース テーブルにバックログが蓄積されると、受信速度が低減されます)。</span><span class="sxs-lookup"><span data-stu-id="221fb-112">If messages start building up at the receive location (for example, file receive folder grows large or outgoing queue is not being drained fast enough) this is an indication that the system is unable to absorb data at a sufficiently fast rate to keep up with the incoming load either due to internal throttling (BizTalk reduces receiving rate if the subscribers are unable to process data fast enough causing backlog buildup in the database tables).</span></span> <span data-ttu-id="221fb-113">ボトルネックの原因がハードウェアの制限にある場合は、スケール アップを試みます。</span><span class="sxs-lookup"><span data-stu-id="221fb-113">In case the bottleneck is caused due to hardware limitations try scaling up.</span></span> <span data-ttu-id="221fb-114">受信ハンドラーにマップされているホストにホスト インスタンス (サーバー) を追加することによってスケール アウトすることもできます。</span><span class="sxs-lookup"><span data-stu-id="221fb-114">It is also possible to scale out by adding a Host Instance (server) to the Host mapped to the receive handler.</span></span> <span data-ttu-id="221fb-115">Perfmon を使用して、システムのリソース使用率を監視します。</span><span class="sxs-lookup"><span data-stu-id="221fb-115">Use Perfmon to monitor the resource utilization on the system.</span></span> <span data-ttu-id="221fb-116">ボトルネックの原因が外部の受信場所でないことを確認することが重要です。</span><span class="sxs-lookup"><span data-stu-id="221fb-116">It is important to confirm that the external receive location is not the cause of the bottleneck.</span></span> <span data-ttu-id="221fb-117">たとえば、頻繁なディスク入出力によってリモートのファイル共有が飽和状態になっていないか、リモートの送信キューをホストしているサーバーが飽和状態になっていないか、HTTP/SOAP の負荷を生成するために使用されているクライアントでスレッドが不足していないかなどを確認します。</span><span class="sxs-lookup"><span data-stu-id="221fb-117">For example, remote file share is saturated due to high disk IO or the server hosting the remote outgoing queue is not saturated or the client used to generate HTTP/SOAP load is not starved on threads.</span></span>  
  
## <a name="processing-bottlenecks"></a><span data-ttu-id="221fb-118">処理のボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-118">Processing Bottlenecks</span></span>  
 <span data-ttu-id="221fb-119">Host Queue - Length のカウント (以下の Perfmon カウンターの表を参照) が高くなっている場合は、オーケストレーションの完了が遅れています。</span><span class="sxs-lookup"><span data-stu-id="221fb-119">If the Host Queue - Length count (see the Perfmon counter table below) is climbing, it indicates that the orchestrations are not completing fast enough.</span></span> <span data-ttu-id="221fb-120">この原因としては、メモリの競合や CPU の飽和が考えられます。</span><span class="sxs-lookup"><span data-stu-id="221fb-120">This could be due to memory contention or CPU saturation.</span></span>  
  
 <span data-ttu-id="221fb-121">オーケストレーション サーバーがボトルネックになっている場合は、Perfmon を使用して原因を特定します。</span><span class="sxs-lookup"><span data-stu-id="221fb-121">If the orchestration servers are the bottleneck, use Perfmon to identify the source.</span></span>  
  
 <span data-ttu-id="221fb-122">サーバーが CPU の制約を受けている場合は、以下の対策を検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-122">If the server is CPU bound, consider the following:</span></span>  
  
-   <span data-ttu-id="221fb-123">ワークフローが複雑な場合は、オーケストレーションを複数の小さなオーケストレーションに分割することを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-123">If the workflow is complex consider splitting the orchestration into multiple smaller orchestrations</span></span>  
  
    > [!NOTE]
    >  <span data-ttu-id="221fb-124">オーケストレーションを複数のワークフローに分割すると、待機時間が増加したり複雑さが増したりする可能性があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-124">Splitting an orchestration into multiple workflows can cause additional latency and add complexity.</span></span>  
  
-   <span data-ttu-id="221fb-125">複雑なマップが使用されている場合は、受信ポートか送信ポートに移動できないかどうかを検討します (どちらのポートが帯域幅に余裕があるかを確認してください)。</span><span class="sxs-lookup"><span data-stu-id="221fb-125">If complex maps are used consider whether they can be moved to the Receive/Send ports (verify which ports have additional bandwidth).</span></span>  
  
-   <span data-ttu-id="221fb-126">ハードウェアのスケール アップを検討するか、可能であれば、追加の処理サーバーを構成してスケール アウトすることを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-126">Consider scaling up the hardware or if possible consider scaling out by configuring an additional processing server.</span></span>  
  
## <a name="transmitting-bottlenecks"></a><span data-ttu-id="221fb-127">送信のボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-127">Transmitting Bottlenecks</span></span>  
 <span data-ttu-id="221fb-128">送信サーバーでリソース (ディスク、メモリ、CPU など) が飽和状態になっている場合は、サーバーのスケール アップを検討するか、可能であれば、送信ホスト サーバーを追加してスケール アウトすることを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-128">If the transmitting server is saturated on resources (for example, disk, memory, CPU), consider scaling-up the server or if possible consider scaling-out to additional send host servers.</span></span> <span data-ttu-id="221fb-129">送信層がボトルネックになる場合、送信先 (BizTalk の外部) でのデータの受信が遅れている可能性もあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-129">The sending tier could become the bottleneck if the destination (external to BizTalk) is unable to receive data fast enough.</span></span> <span data-ttu-id="221fb-130">送信先でのデータの受信が遅れると、メッセージ ボックス データベース (Application SendHostQ) にメッセージが蓄積されます。</span><span class="sxs-lookup"><span data-stu-id="221fb-130">This will cause messages to buildup in the MessageBox database (Application SendHostQ).</span></span>  
  
 <span data-ttu-id="221fb-131">すべてのエンドポイントがトポロジの範囲内にある場合は、原因を送信先で切り分けることを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-131">If at all the endpoints are within the scope of the topology, consider isolating the cause at the destination.</span></span> <span data-ttu-id="221fb-132">たとえば、HTTP/SOAP の場所が負荷を受け取るのに最適な構成になっているか、スケールアウトが可能か、</span><span class="sxs-lookup"><span data-stu-id="221fb-132">For example, is the HTTP/SOAP location optimally configured to receive load or could it be scaled-out?</span></span> <span data-ttu-id="221fb-133">BizTalk によって配信される出力メッセージが多すぎるために送信先でメッセージが蓄積されていないかを確認します。</span><span class="sxs-lookup"><span data-stu-id="221fb-133">Is the destination growing due to excessive output messages delivered by BizTalk?</span></span> <span data-ttu-id="221fb-134">送信先でメッセージが蓄積されている場合は、送信先のメッセージのアーカイブや削除を行うメンテナンス プランを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-134">If yes, consider a maintenance plan to archive and purge the destination messages.</span></span> <span data-ttu-id="221fb-135">たとえば、送信先のフォルダーに多数のファイルがあると、BizTalk サービスによるディスク ドライブへのデータのコミットに深刻な影響を及ぼす可能性があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-135">For example, large numbers of files in a destination folder can severely impact the ability of the BizTalk service to commit data to the disk drive.</span></span>  
  
## <a name="tracking-bottlenecks"></a><span data-ttu-id="221fb-136">追跡のボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-136">Tracking Bottlenecks</span></span>  
 <span data-ttu-id="221fb-137">追跡ホスト インスタンスには、BAM および追跡メッセージ イベントとサービス インスタンスのデータの両方を、メッセージ ボックス データベース (TrackingData テーブル) から BizTalkDTADb データベースや BAMPrimaryImport データベースのテーブルに移動する役割があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-137">The Tracking Host Instance is responsible for moving both BAM & tracked message event and service instance data from the MessageBox database (TrackingData table) to the BizTalkDTADb and/or BAMPrimaryImport database tables.</span></span> <span data-ttu-id="221fb-138">複数のメッセージ ボックス データベースが構成されている場合、追跡ホスト インスタンスはメッセージ ボックスごとに 4 つのスレッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="221fb-138">If multiple MessageBox databases are configured the tracking host instance uses four threads per MessageBox.</span></span>  
  
 <span data-ttu-id="221fb-139">このホスト インスタンスが CPU の制約を受けている可能性があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-139">It is possible that this host instance could get CPU bound.</span></span> <span data-ttu-id="221fb-140">その場合は、サーバーをスケール アップするか、ホストの追跡を有効にした追加のサーバーを構成してスケール アウトすることを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-140">If that is the case consider scaling-up the server or scale-out by configuring an additional server with Host Tracking enabled.</span></span> <span data-ttu-id="221fb-141">複数のホスト インスタンスによって、複数構成のメッセージ ボックスの負荷が自動的に分散されます。</span><span class="sxs-lookup"><span data-stu-id="221fb-141">The multiple host instances will automatically balance load for the multiple MessageBoxes configured.</span></span>  
  
 <span data-ttu-id="221fb-142">メッセージ ボックス データベースの TrackingData テーブルでバックアップが開始されている場合は、通常、BizTalkDTADb データベースや BAMPrimaryImport データベースのデータ管理ジョブが構成されたとおりに実行されていないため、データベースのサイズが増加しています。</span><span class="sxs-lookup"><span data-stu-id="221fb-142">If the TrackingData table in the MessageBox database starts backing up, it is usually because the data maintenance jobs on the BizTalkDTADb and/or BAMPrimaryImport database are not running as configured causing growth of the BizTalkDTADb and/or BAMPrimaryImport database.</span></span> <span data-ttu-id="221fb-143">これらのデータベースのサイズが大きくなりすぎると、それらのテーブルにデータを挿入する追跡ホストの機能に悪影響を及ぼし、追跡データがメッセージ ボックス データベースのテーブルにバックアップされることになります。</span><span class="sxs-lookup"><span data-stu-id="221fb-143">Once these databases grow too large it can have a negative impact on the ability of the tracking host to insert data into these tables causing the tracked data to backup in the MessageBox database tables.</span></span> <span data-ttu-id="221fb-144">メッセージ ボックス -> TrackingData テーブルのサイズの増加は制限の作動につながります。</span><span class="sxs-lookup"><span data-stu-id="221fb-144">The growth of the MessageBox->TrackingData table will cause throttling to kick in.</span></span>  
  
## <a name="other"></a><span data-ttu-id="221fb-145">その他</span><span class="sxs-lookup"><span data-stu-id="221fb-145">Other</span></span>  
 <span data-ttu-id="221fb-146">さまざまな機能がそれぞれ専用の分離ホスト インスタンスで実行されるように展開トポロジを構成します。</span><span class="sxs-lookup"><span data-stu-id="221fb-146">Configure the deployment topology such that different functionality runs in dedicated isolated host instances.</span></span> <span data-ttu-id="221fb-147">これにより、各ホスト インスタンスにそれぞれ固有のリソースのセット (32 ビット システムの場合は 2 GB の仮想メモリ アドレス空間、ハンドル、スレッドなど) が割り当てられます。</span><span class="sxs-lookup"><span data-stu-id="221fb-147">This way each host instance gets its own set of resources (on a 32-bit system, 2GB virtual memory address space, handles, threads).</span></span> <span data-ttu-id="221fb-148">サーバーに複数のホスト インスタンスをホストする余力がある (CPU ヘッドルームやメモリが十分にある) 場合は、すべてのホスト インスタンスを同じ物理コンピューターで実行するように構成できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-148">If the server is powerful enough (sufficient CPU headroom, memory) to host multiple host instances they can all be configured to run on the same physical machine.</span></span> <span data-ttu-id="221fb-149">そうでない場合も、機能を専用のサーバーに移動することにより容易にスケール アウトすることができます。</span><span class="sxs-lookup"><span data-stu-id="221fb-149">If not, this also makes it easy to scale-out by moving the functionality to dedicated servers.</span></span> <span data-ttu-id="221fb-150">同じ機能を複数のサーバーで実行すると、高可用性の構成を実現することもできます。</span><span class="sxs-lookup"><span data-stu-id="221fb-150">Running the same functionality on multiple servers also serves to provide a highly available configuration.</span></span>  
  
## <a name="biztalk-system-performance-counters"></a><span data-ttu-id="221fb-151">BizTalk システム パフォーマンス カウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-151">BizTalk System Performance Counters</span></span>  
  
|<span data-ttu-id="221fb-152">オブジェクト</span><span class="sxs-lookup"><span data-stu-id="221fb-152">Object</span></span>|<span data-ttu-id="221fb-153">Instance</span><span class="sxs-lookup"><span data-stu-id="221fb-153">Instance</span></span>|<span data-ttu-id="221fb-154">カウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-154">Counter</span></span>|<span data-ttu-id="221fb-155">監視の目的</span><span class="sxs-lookup"><span data-stu-id="221fb-155">Monitoring Purpose</span></span>|  
|------------|--------------|-------------|------------------------|  
|<span data-ttu-id="221fb-156">プロセッサ</span><span class="sxs-lookup"><span data-stu-id="221fb-156">Processor</span></span>|<span data-ttu-id="221fb-157">_Total</span><span class="sxs-lookup"><span data-stu-id="221fb-157">_Total</span></span>|<span data-ttu-id="221fb-158">[% プロセッサ時間]</span><span class="sxs-lookup"><span data-stu-id="221fb-158">% Processor Time</span></span>|<span data-ttu-id="221fb-159">リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-159">Resource Contention</span></span>|  
|<span data-ttu-id="221fb-160">Process</span><span class="sxs-lookup"><span data-stu-id="221fb-160">Process</span></span>|<span data-ttu-id="221fb-161">BTSNTSvc</span><span class="sxs-lookup"><span data-stu-id="221fb-161">BTSNTSvc</span></span>|<span data-ttu-id="221fb-162">Virtual Bytes</span><span class="sxs-lookup"><span data-stu-id="221fb-162">Virtual Bytes</span></span>|<span data-ttu-id="221fb-163">メモリ リーク/メモリの肥大化</span><span class="sxs-lookup"><span data-stu-id="221fb-163">Memory Leak/Bloat</span></span>|  
|<span data-ttu-id="221fb-164">Process</span><span class="sxs-lookup"><span data-stu-id="221fb-164">Process</span></span>|<span data-ttu-id="221fb-165">BTSNTSvc</span><span class="sxs-lookup"><span data-stu-id="221fb-165">BTSNTSvc</span></span>|<span data-ttu-id="221fb-166">Private Bytes</span><span class="sxs-lookup"><span data-stu-id="221fb-166">Private Bytes</span></span>|<span data-ttu-id="221fb-167">メモリ リーク/メモリの肥大化</span><span class="sxs-lookup"><span data-stu-id="221fb-167">Memory Leak/Bloat</span></span>|  
|<span data-ttu-id="221fb-168">Process</span><span class="sxs-lookup"><span data-stu-id="221fb-168">Process</span></span>|<span data-ttu-id="221fb-169">BTSNTSvc</span><span class="sxs-lookup"><span data-stu-id="221fb-169">BTSNTSvc</span></span>|<span data-ttu-id="221fb-170">Handle Count</span><span class="sxs-lookup"><span data-stu-id="221fb-170">Handle Count</span></span>|<span data-ttu-id="221fb-171">リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-171">Resource Contention</span></span>|  
|<span data-ttu-id="221fb-172">Process</span><span class="sxs-lookup"><span data-stu-id="221fb-172">Process</span></span>|<span data-ttu-id="221fb-173">BTSNTSvc</span><span class="sxs-lookup"><span data-stu-id="221fb-173">BTSNTSvc</span></span>|<span data-ttu-id="221fb-174">スレッド数</span><span class="sxs-lookup"><span data-stu-id="221fb-174">Thread Count</span></span>|<span data-ttu-id="221fb-175">リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-175">Resource Contention</span></span>|  
|<span data-ttu-id="221fb-176">Physical Disk</span><span class="sxs-lookup"><span data-stu-id="221fb-176">Physical Disk</span></span>|<span data-ttu-id="221fb-177">_Total</span><span class="sxs-lookup"><span data-stu-id="221fb-177">_Total</span></span>|<span data-ttu-id="221fb-178">% Idle Time</span><span class="sxs-lookup"><span data-stu-id="221fb-178">% Idle Time</span></span>|<span data-ttu-id="221fb-179">リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-179">Resource Contention</span></span>|  
|<span data-ttu-id="221fb-180">Physical Disk</span><span class="sxs-lookup"><span data-stu-id="221fb-180">Physical Disk</span></span>|<span data-ttu-id="221fb-181">_Total</span><span class="sxs-lookup"><span data-stu-id="221fb-181">_Total</span></span>|<span data-ttu-id="221fb-182">Current Disk Queue Length</span><span class="sxs-lookup"><span data-stu-id="221fb-182">Current Disk Queue Length</span></span>|<span data-ttu-id="221fb-183">リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-183">Resource Contention</span></span>|  
  
### <a name="cpu-contention"></a><span data-ttu-id="221fb-184">CPU の競合</span><span class="sxs-lookup"><span data-stu-id="221fb-184">CPU Contention</span></span>  
 <span data-ttu-id="221fb-185">プロセッサが飽和状態の場合は、送信とオーケストレーションから受信を分離して、アプリケーションをフラグメント化することを検討します。</span><span class="sxs-lookup"><span data-stu-id="221fb-185">If the processor is saturated consider fragmenting the application by separating the Receiving from the Sending and Orchestration.</span></span> <span data-ttu-id="221fb-186">そのためには、別々のホストを作成して特定の機能 (受信、送信、オーケストレーション、追跡) にマップし、それぞれに専用のサーバーを追加します。</span><span class="sxs-lookup"><span data-stu-id="221fb-186">The way to accomplish this is by creating separate hosts, mapping these hosts to specific functionality (Receive/Send/Orchestrations/Tracking) and adding dedicated servers to these separate hosts.</span></span> <span data-ttu-id="221fb-187">一般に、オーケストレーションは CPU を大量に消費します。したがって、オーケストレーションを別の専用サーバーで実行するようにシステムを構成すると、システム全体のスループットが向上します。</span><span class="sxs-lookup"><span data-stu-id="221fb-187">Orchestration functionality is generally known to be CPU hungry, thus configuring the system such that the orchestrations execute on a separate dedicated server helps improve overall system throughput.</span></span>  
  
 <span data-ttu-id="221fb-188">複数のオーケストレーションが展開されている場合は、それぞれを異なる専用オーケストレーション ホストに参加させることができます。</span><span class="sxs-lookup"><span data-stu-id="221fb-188">If multiple orchestrations are deployed, it is possible to enlist them to different dedicated Orchestration-Hosts.</span></span> <span data-ttu-id="221fb-189">それらの専用オーケストレーション ホストに別々の物理サーバーをマップすると、それぞれのオーケストレーションが分離されるため、同じ物理アドレス空間または同じサーバーで共有されているリソースの競合が発生しなくなります。</span><span class="sxs-lookup"><span data-stu-id="221fb-189">Mapping different physical servers to the dedicated Orchestration-Hosts ensures that the different orchestrations are isolated and do not contend for shared resources either in the same physical address space or on the same server.</span></span>  
  
### <a name="memory-starvation"></a><span data-ttu-id="221fb-190">メモリ不足</span><span class="sxs-lookup"><span data-stu-id="221fb-190">Memory Starvation</span></span>  
 <span data-ttu-id="221fb-191">高スループットのシナリオでは、システム メモリの需要が増大する場合があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-191">High throughput scenarios can have increased demand on system memory.</span></span> <span data-ttu-id="221fb-192">32 ビット プロセスでは、使用できるメモリの量が制限されているため、受信、処理、送信の機能をそれぞれ別のホスト インスタンスに分離して、各ホストに 2 GB のアドレス空間が割り当てられるようにすることをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="221fb-192">Since a 32-bit process is limited by the amount of memory it can consume, it is recommended to separate the Receive/Process/Send functionality into separate Host Instances such that each host receives its own 2GB address space.</span></span> <span data-ttu-id="221fb-193">さらに、複数のホスト インスタンスが同じ物理サーバーで実行されている場合は、実際のメモリからデータをディスクにスワップすることを回避するために 4/8 GB のメモリへのアップグレードに便利です。</span><span class="sxs-lookup"><span data-stu-id="221fb-193">In addition, if multiple Host Instances are running on the same physical server it is useful to upgrade to 4/8GB memory to avoid having to swap data to disk from real memory.</span></span> <span data-ttu-id="221fb-194">長時間のオーケストレーションは、メモリが肥大化の原因となった、したがって制限が作動し、割り当てられたメモリに保持できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-194">Long running orchestrations can hold onto allocated memory longer causing memory bloat and thus throttling to kick in.</span></span> <span data-ttu-id="221fb-195">サイズの大きいメッセージは、高いメモリ消費量もあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-195">Large messages can also cause high memory consumption.</span></span>  
  
 <span data-ttu-id="221fb-196">削減し、サイズの大きいメッセージの処理中に、このメモリ肥大化の問題を克服することができます、**内部メッセージ キュー サイズ**と**CPU あたりのインプロセス メッセージ**特定ホスト用の値。</span><span class="sxs-lookup"><span data-stu-id="221fb-196">It is possible to overcome this memory bloat problem when large messages are being processed by lowering the **Internal Message Queue Size** and **In-process Messages per CPU** values for the specific host.</span></span>  
  
### <a name="disk-contention"></a><span data-ttu-id="221fb-197">ディスクの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-197">Disk Contention</span></span>  
 <span data-ttu-id="221fb-198">かどうか (たとえば、ファイルや MSMQ トランスポートなど)、ディスクが飽和状態にマルチ スピンドルへのアップグレードや raid ディスクのストライピングを検討してください。 1 + 0。</span><span class="sxs-lookup"><span data-stu-id="221fb-198">If the disks are saturated (for example, File/MSMQ transports) consider upgrading to multiple spindles and striping the disks with RAID 1+0.</span></span> <span data-ttu-id="221fb-199">さらに、ファイル トランスポートを使用するたびにすることが重要するフォルダー (受信と送信の両方) は大きくなりすぎないことを確認 (> 50,000 ファイル)。</span><span class="sxs-lookup"><span data-stu-id="221fb-199">In addition whenever using the FILE transport it is important to ensure that the folders (both Receive and Send) do not grow too large (>50,000 files).</span></span>  
  
 <span data-ttu-id="221fb-200">BizTalk Server では、以下で説明するさまざまな理由によりシステムの受信データが制限された場合、受信フォルダーのサイズが大きくなることがあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-200">The Receive folder can grow large if BizTalk Server chooses to throttle incoming data into the system due to various reasons mentioned below.</span></span> <span data-ttu-id="221fb-201">また、送信フォルダーのサイズが大きくなると、BizTalk Server による追加データの書き込みに影響を及ぼす可能性もあるため、送信フォルダーからデータを移動することも重要です。</span><span class="sxs-lookup"><span data-stu-id="221fb-201">It is also important to move data from the send folder so that growth in this folder does not impact the ability of BizTalk Server to write additional data.</span></span> <span data-ttu-id="221fb-202">非トランザクション MSMQ キューについては、BizTalk Server のディスクの競合を減らすため、受信キューをリモートに作成することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="221fb-202">For non-transactional MSMQ queues, it is recommended to remotely create the receive queues so that disk contention is reduced on the BizTalk server.</span></span>  
  
 <span data-ttu-id="221fb-203">この構成 (リモートの非トランザクション キュー) では、キューをホストするリモート サーバーのクラスター化が可能になるため、高可用性のメリットもあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-203">This configuration (remote non-transactional queues) also provides the added benefit of high availability as the remote server hosting the queue can be clustered.</span></span>  
  
### <a name="other-system-resource-contention"></a><span data-ttu-id="221fb-204">その他のシステム リソースの競合</span><span class="sxs-lookup"><span data-stu-id="221fb-204">Other System Resource Contention</span></span>  
 <span data-ttu-id="221fb-205">構成されているトランスポートの性質によっては、IIS のようなシステム リソースを HTTP/SOAP 用に構成する必要がある場合もあります (MaxIOThreads や MaxWorkerThreads など)。</span><span class="sxs-lookup"><span data-stu-id="221fb-205">Depending on the nature of the transport configured it may be necessary to configure system resources like IIS for HTTP/SOAP (for example, MaxIOThreads, MaxWorkerThreads).</span></span>  
  
### <a name="downstream-bottlenecks"></a><span data-ttu-id="221fb-206">下流のボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-206">Downstream Bottlenecks</span></span>  
 <span data-ttu-id="221fb-207">下流システムが BizTalk からのデータを十分な速さで受信できない場合、その出力データが BizTalk データベースにバックアップされます。その結果、データベースが肥大化して制限が作動し、受信パイプが縮小されるため、BizTalk システム全体のスループットに影響します。</span><span class="sxs-lookup"><span data-stu-id="221fb-207">If the downstream system is unable to receive data fast enough from BizTalk this output data will back up within the BizTalk databases resulting in bloat causing throttling to kick in shrinking the receive pipe thereby impacting the overall throughput of the BizTalk system.</span></span> <span data-ttu-id="221fb-208">この状況を直接示すのはスプールの増大です。</span><span class="sxs-lookup"><span data-stu-id="221fb-208">A direct indication of this would be Spool growth.</span></span>  
  
### <a name="throttling-impact"></a><span data-ttu-id="221fb-209">制限の影響</span><span class="sxs-lookup"><span data-stu-id="221fb-209">Throttling Impact</span></span>  
 <span data-ttu-id="221fb-210">システムが回復不可能な状態にならないように、最終的には制限が作動します。</span><span class="sxs-lookup"><span data-stu-id="221fb-210">Throttling will ultimately kick in to protect the system from reaching an unrecoverable state.</span></span> <span data-ttu-id="221fb-211">したがって制限は、システムが正常に機能しているかどうかを確認し、問題の原因を特定するための場所として適しています。</span><span class="sxs-lookup"><span data-stu-id="221fb-211">Thus throttling is a good place to verify whether the system is functioning normally and discover the source of the problem.</span></span> <span data-ttu-id="221fb-212">制限の状態からボトルネックの原因を特定できたら、他のパフォーマンス カウンターを分析して問題の原因にドリル ダウンします。</span><span class="sxs-lookup"><span data-stu-id="221fb-212">After the cause of the bottleneck has been identified from the throttling state, analyze the other performance counters to drill down into the source of the problem.</span></span>  
  
 <span data-ttu-id="221fb-213">たとえば、メッセージ ボックス データベースで競合が増加している場合、その原因としては CPU 使用率の増加が考えられます。さらに、CPU 使用率の増加の原因としてはディスクへの過剰なページングが、その原因としてはメモリの不足が、それぞれ考えられます。</span><span class="sxs-lookup"><span data-stu-id="221fb-213">For example, high contention on the MessageBox database could be due to high CPU usage, which could be caused due to excessively paging to disk which could be caused due to low memory conditions.</span></span> <span data-ttu-id="221fb-214">メッセージ ボックスで競合が増加する原因としては、その他にロックの競合の増加も考えられます。ロックの競合が増加する原因としては、ディスク ドライブが飽和状態になっていることが考えられます。</span><span class="sxs-lookup"><span data-stu-id="221fb-214">High contention on the MessageBox could also be caused due to high lock contention which could be due to saturated disk drives.</span></span>  
  
## <a name="biztalk-application-counters"></a><span data-ttu-id="221fb-215">BizTalk アプリケーション カウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-215">BizTalk Application Counters</span></span>  
  
|<span data-ttu-id="221fb-216">オブジェクト</span><span class="sxs-lookup"><span data-stu-id="221fb-216">Object</span></span>|<span data-ttu-id="221fb-217">Instance</span><span class="sxs-lookup"><span data-stu-id="221fb-217">Instance</span></span>|<span data-ttu-id="221fb-218">カウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-218">Counter</span></span>|<span data-ttu-id="221fb-219">説明</span><span class="sxs-lookup"><span data-stu-id="221fb-219">Description</span></span>|  
|------------|--------------|-------------|-----------------|  
|<span data-ttu-id="221fb-220">BizTalk Messaging</span><span class="sxs-lookup"><span data-stu-id="221fb-220">BizTalk Messaging</span></span>|<span data-ttu-id="221fb-221">RxHost</span><span class="sxs-lookup"><span data-stu-id="221fb-221">RxHost</span></span>|<span data-ttu-id="221fb-222">Documents Received/Sec</span><span class="sxs-lookup"><span data-stu-id="221fb-222">Documents Received/Sec</span></span>|<span data-ttu-id="221fb-223">受信速度</span><span class="sxs-lookup"><span data-stu-id="221fb-223">Incoming Rate</span></span>|  
|<span data-ttu-id="221fb-224">BizTalk Messaging</span><span class="sxs-lookup"><span data-stu-id="221fb-224">BizTalk Messaging</span></span>|<span data-ttu-id="221fb-225">TxHost</span><span class="sxs-lookup"><span data-stu-id="221fb-225">TxHost</span></span>|<span data-ttu-id="221fb-226">Documents Processed/Sec</span><span class="sxs-lookup"><span data-stu-id="221fb-226">Documents Processed/Sec</span></span>|<span data-ttu-id="221fb-227">送信速度</span><span class="sxs-lookup"><span data-stu-id="221fb-227">Outgoing Rate</span></span>|  
|<span data-ttu-id="221fb-228">XLANG/s Orchestrations</span><span class="sxs-lookup"><span data-stu-id="221fb-228">XLANG/s Orchestrations</span></span>|<span data-ttu-id="221fb-229">PxHost</span><span class="sxs-lookup"><span data-stu-id="221fb-229">PxHost</span></span>|<span data-ttu-id="221fb-230">Orchestrations Completed/Sec.</span><span class="sxs-lookup"><span data-stu-id="221fb-230">Orchestrations Completed/Sec.</span></span>|<span data-ttu-id="221fb-231">処理速度</span><span class="sxs-lookup"><span data-stu-id="221fb-231">Processing Rate</span></span>|  
|<span data-ttu-id="221fb-232">BizTalk: メッセージ ボックス: 一般的なカウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-232">BizTalk : MessageBox: General Counters</span></span>|<span data-ttu-id="221fb-233">MsgBoxName</span><span class="sxs-lookup"><span data-stu-id="221fb-233">MsgBoxName</span></span>|<span data-ttu-id="221fb-234">Spool Size</span><span class="sxs-lookup"><span data-stu-id="221fb-234">Spool Size</span></span>|<span data-ttu-id="221fb-235">すべてのホスト キューの合計サイズ</span><span class="sxs-lookup"><span data-stu-id="221fb-235">Cumulative size of all Host Queues</span></span>|  
|<span data-ttu-id="221fb-236">BizTalk: メッセージ ボックス: 一般的なカウンター</span><span class="sxs-lookup"><span data-stu-id="221fb-236">BizTalk : MessageBox: General Counters</span></span>|<span data-ttu-id="221fb-237">MsgBoxName</span><span class="sxs-lookup"><span data-stu-id="221fb-237">MsgBoxName</span></span>|<span data-ttu-id="221fb-238">Tracking Data Size</span><span class="sxs-lookup"><span data-stu-id="221fb-238">Tracking Data Size</span></span>|<span data-ttu-id="221fb-239">メッセージ ボックスの TrackingData テーブルのサイズ</span><span class="sxs-lookup"><span data-stu-id="221fb-239">Size of TrackingData table on the MessageBox</span></span>|  
|<span data-ttu-id="221fb-240">BizTalk:MessageBox:Host Counters</span><span class="sxs-lookup"><span data-stu-id="221fb-240">BizTalk:MessageBox:Host Counters</span></span>|<span data-ttu-id="221fb-241">PxHost:MsgBoxName</span><span class="sxs-lookup"><span data-stu-id="221fb-241">PxHost:MsgBoxName</span></span>|<span data-ttu-id="221fb-242">Host Queue - Length</span><span class="sxs-lookup"><span data-stu-id="221fb-242">Host Queue - Length</span></span>|<span data-ttu-id="221fb-243">特定のホスト キューに存在するメッセージの数</span><span class="sxs-lookup"><span data-stu-id="221fb-243">Number of messages in the specific Host Queue</span></span>|  
|<span data-ttu-id="221fb-244">BizTalk:MessageBox:Host Counters</span><span class="sxs-lookup"><span data-stu-id="221fb-244">BizTalk:MessageBox:Host Counters</span></span>|<span data-ttu-id="221fb-245">TxHost:MsgBoxName</span><span class="sxs-lookup"><span data-stu-id="221fb-245">TxHost:MsgBoxName</span></span>|<span data-ttu-id="221fb-246">Host Queue - Length</span><span class="sxs-lookup"><span data-stu-id="221fb-246">Host Queue - Length</span></span>|<span data-ttu-id="221fb-247">特定のホスト キューに存在するメッセージの数</span><span class="sxs-lookup"><span data-stu-id="221fb-247">Number of messages in the specific Host Queue</span></span>|  
|<span data-ttu-id="221fb-248">BizTalk:Message Agent</span><span class="sxs-lookup"><span data-stu-id="221fb-248">BizTalk:Message Agent</span></span>|<span data-ttu-id="221fb-249">RxHost</span><span class="sxs-lookup"><span data-stu-id="221fb-249">RxHost</span></span>|<span data-ttu-id="221fb-250">Database Size</span><span class="sxs-lookup"><span data-stu-id="221fb-250">Database Size</span></span>|<span data-ttu-id="221fb-251">公開 (PxHost) キューのサイズ</span><span class="sxs-lookup"><span data-stu-id="221fb-251">Size of publishing (PxHost) Queue</span></span>|  
|<span data-ttu-id="221fb-252">BizTalk:Message Agent</span><span class="sxs-lookup"><span data-stu-id="221fb-252">BizTalk:Message Agent</span></span>|<span data-ttu-id="221fb-253">PxHost</span><span class="sxs-lookup"><span data-stu-id="221fb-253">PxHost</span></span>|<span data-ttu-id="221fb-254">Database Size</span><span class="sxs-lookup"><span data-stu-id="221fb-254">Database Size</span></span>|<span data-ttu-id="221fb-255">公開 (TxHost) キューのサイズ</span><span class="sxs-lookup"><span data-stu-id="221fb-255">Size of publishing (TxHost) Queue</span></span>|  
|<span data-ttu-id="221fb-256">BizTalk:Message Agent</span><span class="sxs-lookup"><span data-stu-id="221fb-256">BizTalk:Message Agent</span></span>|<span data-ttu-id="221fb-257">HostName</span><span class="sxs-lookup"><span data-stu-id="221fb-257">HostName</span></span>|<span data-ttu-id="221fb-258">Message Delivery Throttling State</span><span class="sxs-lookup"><span data-stu-id="221fb-258">Message Delivery Throttling State</span></span>|<span data-ttu-id="221fb-259">XLANG と送信トランスポートに影響</span><span class="sxs-lookup"><span data-stu-id="221fb-259">Affects XLANG and Outbound transports</span></span>|  
|<span data-ttu-id="221fb-260">BizTalk:Message Agent</span><span class="sxs-lookup"><span data-stu-id="221fb-260">BizTalk:Message Agent</span></span>|<span data-ttu-id="221fb-261">HostName</span><span class="sxs-lookup"><span data-stu-id="221fb-261">HostName</span></span>|<span data-ttu-id="221fb-262">Message Publishing Throttling State</span><span class="sxs-lookup"><span data-stu-id="221fb-262">Message Publishing Throttling State</span></span>|<span data-ttu-id="221fb-263">XLANG と受信トランスポートに影響</span><span class="sxs-lookup"><span data-stu-id="221fb-263">Affects XLANG and Inbound transports</span></span>|  
  
### <a name="where-do-i-start"></a><span data-ttu-id="221fb-264">監視の開始</span><span class="sxs-lookup"><span data-stu-id="221fb-264">Where do I start?</span></span>  
 <span data-ttu-id="221fb-265">監視、 **Message Delivery Throttling State**と**Message Publishing Throttling State**各ホストのインスタンスが、通常をお勧めします。</span><span class="sxs-lookup"><span data-stu-id="221fb-265">Monitoring the **Message Delivery Throttling State** and the **Message Publishing Throttling State** for each host instance is usually a good place to start.</span></span> <span data-ttu-id="221fb-266">これらのカウンターの値が 0 でない場合、BizTalk システム内で制限が発生していることがわかります。そこから、ボトルネックの原因をさらに分析することができます。</span><span class="sxs-lookup"><span data-stu-id="221fb-266">If the value of these counters is not zero it is indicative that throttling is happening within the BizTalk system and it is possible to further analyze the cause of the bottleneck.</span></span> <span data-ttu-id="221fb-267">その他のパフォーマンス カウンターの説明については、[データベース層のボトルネックを識別する](http://msdn.microsoft.com/library/f1dc58b5-73b0-41b5-9a1e-c0698485c732)を参照してください。</span><span class="sxs-lookup"><span data-stu-id="221fb-267">For descriptions on the other performance counters, see [Identifying Bottlenecks in the Database Tier](http://msdn.microsoft.com/library/f1dc58b5-73b0-41b5-9a1e-c0698485c732).</span></span>  
  
## <a name="backlog-buildup"></a><span data-ttu-id="221fb-268">バックログの蓄積</span><span class="sxs-lookup"><span data-stu-id="221fb-268">Backlog Buildup</span></span>  
 <span data-ttu-id="221fb-269">1 つの受信メッセージに対して 1 つの処理と送信が行われる 1 対 1 の展開シナリオで、送信速度が受信速度と等しくない場合は、システムのどこかでバックログが蓄積されています。</span><span class="sxs-lookup"><span data-stu-id="221fb-269">For a 1-1 deployment scenario where 1 message received results in 1 message processed and transmitted, if the Outgoing Rate does not equal the Incoming Rate, a backlog is building up somewhere in the system.</span></span> <span data-ttu-id="221fb-270">そのような場合は Spool Size を監視します。</span><span class="sxs-lookup"><span data-stu-id="221fb-270">For such a situation it is possible to monitor the Spool Size.</span></span>  
  
 <span data-ttu-id="221fb-271">Spool Size が直線的に増加している場合は、その原因がどのアプリケーション キューにあるのかを確認することによって、さらにドリル ダウンを進めることができます。</span><span class="sxs-lookup"><span data-stu-id="221fb-271">If the Spool is growing linearly, it is possible to further drill down by verifying which Application Queue is responsible for the Spool growth.</span></span>  
  
 <span data-ttu-id="221fb-272">サイズが増加しているアプリケーション キューがないのに Spool Size が増加し続けている場合は、Purge ジョブの処理が追いついていない可能性があります。その原因としては、エージェントが実行されていないか、SQL Server で他のシステム リソースが競合していることが考えられます。</span><span class="sxs-lookup"><span data-stu-id="221fb-272">If none of the application queues are growing and the Spool continues to grow it could mean that the purge jobs are unable to keep up either due to the agent not running or other system resource contention on the SQL server.</span></span>  
  
 <span data-ttu-id="221fb-273">サイズが増加しているアプリケーション キューがある場合は、その増加の原因を診断することが重要です。</span><span class="sxs-lookup"><span data-stu-id="221fb-273">If one of the application queues are growing, it is important to diagnose the cause of this growth.</span></span> <span data-ttu-id="221fb-274">そのアプリケーション キューの排出ができなくなっているシステムでシステム リソースを監視します (たとえば、サーバーの CPU が不足すると Orchestration Host-Q のサイズが増加します)。</span><span class="sxs-lookup"><span data-stu-id="221fb-274">Monitor the system resources on the system that is unable to drain the specific application queue (for example, Orchestration Host-Q is growing due to CPU starvation on the server).</span></span> <span data-ttu-id="221fb-275">さらに、そのホスト インスタンスの制限カウンターの値を確認します。</span><span class="sxs-lookup"><span data-stu-id="221fb-275">In addition verify the values of the throttling counter for the specific host instance.</span></span>  
  
 <span data-ttu-id="221fb-276">Delivery/Publishing State が 0 でない場合は、値を調べて制限の原因を確認します (たとえば、メモリのしきい値を超えている場合や、インフライト メッセージの数が多すぎる場合などが考えられます)。</span><span class="sxs-lookup"><span data-stu-id="221fb-276">If the Delivery/Publishing State is not zero, check the value to confirm the reason for throttling (for example, memory threshold exceeded, in-flight message count too high etc.).</span></span>  
  
## <a name="f1-profiler"></a><span data-ttu-id="221fb-277">F1 Profiler</span><span class="sxs-lookup"><span data-stu-id="221fb-277">F1 Profiler</span></span>  
 <span data-ttu-id="221fb-278">パフォーマンス カウンターを使用すると、ボトルネックのだいたいの場所をすばやく特定できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-278">By using performance counters, it is possible to quickly detect at a high level the location of the bottleneck.</span></span> <span data-ttu-id="221fb-279">しかし、場所が絞り込んだ後、問題を解消するにはさらにコードにドリル ダウンする必要がある場合もあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-279">However, once narrowed down, it may be necessary to drill down further into the code to help alleviate the problem.</span></span> <span data-ttu-id="221fb-280">Visual Studio に付属の F1 Profiler は、コードのサイクルが最も消費されている場所を診断するのに非常に便利なツールです。</span><span class="sxs-lookup"><span data-stu-id="221fb-280">The F1 Profiler that ships with Visual Studio can be a very helpful tool to help diagnose where the code is spending most of its cycles.</span></span>  
  
 <span data-ttu-id="221fb-281">シンボルは、より意味のあるスタックを作成するうえで (アンマネージ コードの場合は特に) 重要です。</span><span class="sxs-lookup"><span data-stu-id="221fb-281">Symbols are important to help with creating a more meaningful stack (especially for unmanaged code).</span></span> <span data-ttu-id="221fb-282">たとえば F1 Profiler では、API 呼び出しが戻るまでに要する呼び出しの数や時間を特定できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-282">For example, the F1-Profiler can help pinpoint the number of invocations and the amount of time an API call takes to return.</span></span> <span data-ttu-id="221fb-283">スタックをさらにドリル ダウンすることによって、待機時間の増加の根本原因を特定できる場合もあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-283">Drilling further down the stack, it may be possible to detect the underlying cause of the high latency.</span></span> <span data-ttu-id="221fb-284">たとえば、データベース クエリへのブロッキング呼び出しが原因になっている場合や、呼び出しがイベントを待機しているだけである場合などがあります。</span><span class="sxs-lookup"><span data-stu-id="221fb-284">It could be a blocking call to a database query or simply a call to wait on an event.</span></span>  
  
## <a name="l2l3-cache"></a><span data-ttu-id="221fb-285">L2/L3 キャッシュ</span><span class="sxs-lookup"><span data-stu-id="221fb-285">L2/L3 Cache</span></span>  
 <span data-ttu-id="221fb-286">ハードウェアの観点からは、オンボードの CPU キャッシュを利用した場合に、最も大きな効果が得られます。</span><span class="sxs-lookup"><span data-stu-id="221fb-286">The biggest benefits (from a hardware perspective) that can be gained is by utilizing onboard CPU cache.</span></span> <span data-ttu-id="221fb-287">CPU キャッシュが大きければキャッシュのヒット率が高くなり、システムでメモリからディスクへのデータのページングを行う必要が少なくなります。</span><span class="sxs-lookup"><span data-stu-id="221fb-287">Higher CPU cache helps increase cache hit rate reducing the need for the system to page data in and out of memory to disk.</span></span>  
  
## <a name="64-bit-performance-bottlenecks"></a><span data-ttu-id="221fb-288">64 ビットのパフォーマンスのボトルネック</span><span class="sxs-lookup"><span data-stu-id="221fb-288">64-Bit Performance Bottlenecks</span></span>  
 <span data-ttu-id="221fb-289">64 ビット システムのパフォーマンスが 32 ビット システムより低く見える場合があります。</span><span class="sxs-lookup"><span data-stu-id="221fb-289">Performance on 64-bit systems may appear lower than what can be achieved on 32-bit systems.</span></span> <span data-ttu-id="221fb-290">原因はいくつか考えられますが、最も重要な原因はメモリです。</span><span class="sxs-lookup"><span data-stu-id="221fb-290">This is possible due to a couple of reasons, the most important one being memory.</span></span>  
  
 <span data-ttu-id="221fb-291">2 GB のメモリを搭載した 32 ビット システムでパフォーマンスを測定し、その結果を 2 GB のメモリを搭載した同様の 64 ビット システムと比較する場合、厳密には同じ条件の比較にはなりません。</span><span class="sxs-lookup"><span data-stu-id="221fb-291">Measuring performance on a 32-bit system with 2-GB of memory and comparing the results to what can be achieved on a similar 64-bit system with 2-GB of memory is not a true apples to apples comparison.</span></span> <span data-ttu-id="221fb-292">64 ビット システムがディスク入出力の制約を受けていたり (% Disk Idle time が低く、Disk Queue Length が高い)、CPU の制約を受けていたり (CPU が上限に達し、Context Switching も高い) するように見えますが、</span><span class="sxs-lookup"><span data-stu-id="221fb-292">The 64-bit system will appear to be disk-IO bound (low % Disk Idle time & high Disk Queue Length) and CPU bound (max CPU & high Context Switching).</span></span> <span data-ttu-id="221fb-293">これは、64 ビット システムのファイル入出力処理により多くのリソースが必要とされるということではありません。</span><span class="sxs-lookup"><span data-stu-id="221fb-293">However, this is not because performing file IO on a 64-bit system is more expensive.</span></span>  
  
 <span data-ttu-id="221fb-294">64 ビット システムはより多くのメモリを必要とするため (64 ビット アドレッシング)、使用可能な 2 GB のメモリのほとんどが OS によって使用されます。</span><span class="sxs-lookup"><span data-stu-id="221fb-294">The 64-bit system is more memory hungry (64-bit addressing) which results in the OS consuming most of the 2-GB available memory.</span></span> <span data-ttu-id="221fb-295">そのため、他のほとんどの操作でディスクへのページングが発生し、ファイル サブシステムに負荷がかかります。</span><span class="sxs-lookup"><span data-stu-id="221fb-295">Once this happens most other operations cause paging to disk which stresses the file subsystem.</span></span> <span data-ttu-id="221fb-296">結果として、データとコードの両方のページングに CPU サイクルが消費されるだけでなく、ディスクの待機時間も増加します。</span><span class="sxs-lookup"><span data-stu-id="221fb-296">The system now not only spends CPU cycles paging in/out of memory both data and code but is also impacted by the high disk latency cost.</span></span> <span data-ttu-id="221fb-297">それが、ディスクの競合と CPU 消費の増加として現れます。</span><span class="sxs-lookup"><span data-stu-id="221fb-297">This manifests itself as both higher disk contention and higher CPU consumption.</span></span>  
  
 <span data-ttu-id="221fb-298">この問題を解消するには、メモリを (できれば 8 GB に) アップグレードしてサーバーをスケールアップします。</span><span class="sxs-lookup"><span data-stu-id="221fb-298">The way to alleviate this problem is to scale-up the server by upgrading the memory (ideally 8-GB).</span></span> <span data-ttu-id="221fb-299">ただし、問題の原因がメモリ不足に起因する CPU 不足でない場合は、メモリを追加してもスループットは向上しません。</span><span class="sxs-lookup"><span data-stu-id="221fb-299">However, adding more memory will not help improve throughput unless the source of the problem is CPU starvation due to low memory conditions.</span></span>  
  
## <a name="using-bam-to-identify-bottlenecks-and-high-latency-issues"></a><span data-ttu-id="221fb-300">BAM によるボトルネックと待機時間の問題の特定</span><span class="sxs-lookup"><span data-stu-id="221fb-300">Using BAM to identify bottlenecks and high latency issues</span></span>  
 <span data-ttu-id="221fb-301">待機時間の短縮が重視される場合は、BAM を使用すると、BizTalk システム内の各ステージの完了にかかる時間を測定できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-301">In situations where low latency is important, you can use BAM to measure the time the system takes to complete each stage within the BizTalk system.</span></span> <span data-ttu-id="221fb-302">追跡したメッセージ イベントおよびサービス インスタンス データを使用して、メッセージの状態をデバッグしたり、メッセージのルーティングの問題の原因を診断したりすることができますが、BAM を使用すると、メッセージ フローのさまざまなポイントを追跡することができます。</span><span class="sxs-lookup"><span data-stu-id="221fb-302">Although  tracked message event and service instance data can be used to debug the state of messages and diagnose the source of problems in routing messages, BAM can be used to track various points through the message flow.</span></span> <span data-ttu-id="221fb-303">BAM 追跡プロファイルを作成することにより (継続を含むアクティビティを定義します)、システムのさまざまな部分の間の待機時間を測定して、ワークフロー プロセス内で最もコストの大きいステージを追跡できます。</span><span class="sxs-lookup"><span data-stu-id="221fb-303">By creating a BAM tracking profile (defining an activity with continuations), you can measure latency between different parts of the system to help track the most expensive stages within the workflow process.</span></span>